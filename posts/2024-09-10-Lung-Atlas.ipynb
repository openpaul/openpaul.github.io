{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "+++\n",
    "title = 'Digging into the Human Lung Cell Atlas'\n",
    "date = 2024-09-10T20:00:00+00:00\n",
    "draft = false\n",
    "summary ='Exploring the data avaliable in the Human Lung Cell Atlas'\n",
    "+++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human cell atlas project is growing and I want to know how to use it. \n",
    "\n",
    "[The Human Lung Cell Atlas (HLCA)](https://www.nature.com/articles/s41591-023-02327-2) was published in 2023. It has ~2.3 Million cells and can be downloaded here: [data.humancellatlas.org/hca-bio-networks/lung/atlases/lung-v1-0](https://data.humancellatlas.org/hca-bio-networks/lung/atlases/lung-v1-0)\n",
    "\n",
    "In this notebook I will download the atlas and explore the data that is provided. For me this is a way to learn about a new resource I am not yet familiar with, but would like to understand better. I love that the resource is freely accessible and hope I can make use of it in the future. \n",
    "\n",
    "## Downloading the HLCA\n",
    "\n",
    "Downloading is very easy but as the file is 20 GB, a bit of storage space is required:\n",
    "\n",
    "```sh\n",
    "wget https://datasets.cellxgene.cziscience.com/8d84ba15-d367-4dce-979c-85da70b868a2.h5ad\n",
    "```\n",
    "\n",
    "Now that the data is there I need to open it. For that I will set up a new mamba environment:\n",
    "\n",
    "```sh\n",
    "mamba create -n HLCA python==3.11 uv==0.3.3\n",
    "mamba activate HLCA\n",
    "uv pip install plotnine==0.13.6 scanpy==1.10.2 \n",
    "```\n",
    "\n",
    "With that sorted I can get started.\n",
    "\n",
    "## Loading the Data\n",
    "\n",
    "To handle the dataset I will be using [scanpy](https://scanpy.readthedocs.io/en/stable/), a python package for Single-Cell analysis. As the dataset is very large and my machine only has 32GB of RAM, I will have to work around that. To get started I load the file in `backed` mode, which does not load the entire file into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "hlca = sc.read_h5ad(\"./data/HLCA/8d84ba15-d367-4dce-979c-85da70b868a2.h5ad\", backed='r')\n",
    "print(hlca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of metadata and other data here. After a bit of reading I found out that the count matrix data is located in the `.raw.X` attribute  while transformed values are in `.X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlca.X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know from the web portal that the dataset contains 2.3 Million cells, meaning the dataset contains exactly 2282447 cells with 56239 different transcript columns.\n",
    "\n",
    "I love seeing the raw data, to get a feel for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlca.X[:10, :10].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with the data I will need access to the transcript names, those are store in the `var_names` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlca.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I have loaded the data and I have full access to both the raw and the log-transformed counts. Next I want to dive further into the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting UMAPs\n",
    "\n",
    "I would love to see the data as a UMAP. The authors actually included a UMAP representation of the data, which lets me avoid computing the UMAP locally.\n",
    "\n",
    "I am going to use plotnine here instead of using the integrated plotting functions, because I want to have more control. But the [plotting](https://scanpy.readthedocs.io/en/stable/api/plotting.html) functions of scanpy are very nice to have.\n",
    "\n",
    "To get started and be able to work with this large dataset on my computer, I will subsample randomly to a more convenient size for my personal computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Randomly sample from the cells, to make exploration a bit easier\n",
    "n = 10000\n",
    "index = range(len(hlca.obsm[\"X_umap\"]))\n",
    "cell_index = pd.Series(index).sample(n=n, random_state=1).values\n",
    "hlca_small = hlca[cell_index, :].to_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this smaller dataset I won't be able to perform robust analysis, at least I am losing a lot of statistical power, but for exploring the dataset and the options scanpy offers this is much easier. \n",
    "\n",
    "\n",
    "As mentioned before, the dataset already contains a batch corrected low dimensionality embedding of all cells. This can be accessed using the `X_umap` key. \n",
    "\n",
    "If you want to interactively explore this data yourself you can also checkout [cellxgene.cziscience.com/e/9f222629-9e39-47d0-b83f-e08d610c7479.cxg](https://cellxgene.cziscience.com/e/9f222629-9e39-47d0-b83f-e08d610c7479.cxg/), where you can see the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "df= pd.DataFrame(hlca_small.obsm[\"X_umap\"])\n",
    "df.columns = [\"UMAP1\", \"UMAP2\"]\n",
    "(\n",
    "        p9.ggplot(df, p9.aes(x=\"UMAP1\", y=\"UMAP2\"))\n",
    "        + p9.geom_point(size=2, stroke=0.2, fill=\"#4287f5\")\n",
    "    \n",
    "        + p9.labs(\n",
    "            title=f\"UMAP of {len(df)} random cells\",\n",
    "            subtitle=\"Each Cell is a Point\",\n",
    "            x=\"Component 1\",\n",
    "            y=\"Component 2\",\n",
    "        )\n",
    "        + p9.theme_light()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am curious about some of the annotations. So I will color the plot by some of the metadata provided. These are the features to choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(hlca_small.obs.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is quite a lot of features, I first make a plotting function that allows me to color by a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metadata(df: pd.DataFrame, feature: list, feature_name: str, width: int = 6):\n",
    "    df[\"feature\"] = feature\n",
    "    return (\n",
    "        p9.ggplot(df, p9.aes(x=\"UMAP1\", y=\"UMAP2\", fill = \"feature\"))\n",
    "        + p9.geom_point(size=2, stroke=0.2)\n",
    "    \n",
    "        + p9.labs(\n",
    "            title=f\"UMAP of {len(df)} random cells\",\n",
    "            subtitle=f\"Each Cell is a Point, colored by {feature_name}\",\n",
    "            x=\"Component 1\",\n",
    "            y=\"Component 2\",\n",
    "            fill=feature_name\n",
    "        )\n",
    "        + p9.theme_light() +\n",
    "        p9.theme(\n",
    "         figure_size=(width, 5)\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can plot for example the Sequencing Platform data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature  = hlca_small.obs.sequencing_platform.values.tolist()\n",
    "plot_metadata(df, feature, \"Sequencing Platform\", width = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the Study from which the data was sourced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature  = hlca_small.obs.study.values.tolist()\n",
    "plot_metadata(df, feature, \"Study\", width = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the `Smoking Status`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature  = hlca_small.obs.smoking_status.values.tolist()\n",
    "plot_metadata(df, feature, \"Smoking Status\", width = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the tissue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature  = hlca_small.obs.tissue.values.tolist()\n",
    "plot_metadata(df, feature, \"Tissue\", width = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is pretty interesting to look at and I could spend hours now looking at each feature. A few features I still need to understand. I see in the feature table each 5 labels for:\n",
    "\n",
    "- original_ann_level_1\n",
    "- ann_level_1\n",
    "- transf_ann_level_1_label\n",
    "- transf_ann_level_1_uncert\n",
    "\n",
    "These seem to be annotation levels. I would like to understand where they come from. For that I am turning to the paper.\n",
    "\n",
    "The core HLCA annotations were transferred (`transf`) to the extended atlas using ''scArches k nearest neighbor-based label transfer algorithm''. This explains where the transfer labels come from. \n",
    "\n",
    "The columns `_uncert` should contain the 'uncertainty score' associated with that label transfer.   \n",
    "\n",
    "If I understand correctly, the `original_ann_level_1`  to contain labels annotated manually while the `ann_level_1` contains the inferred labels. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hlca_small.obs[[\"original_ann_level_1\", \"ann_level_1\", \"transf_ann_level_1_label\", \"transf_ann_level_1_uncert\"]].head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can color the UMAP by the annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature  = hlca_small.obs.ann_level_1.values.tolist()\n",
    "plot_metadata(df, feature, \"ann_level_1\", width = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I think I understand those annotation columns correctly.  And I can go ever deeper into the tissue/cell types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature  = hlca_small.obs.ann_level_2.values.tolist()\n",
    "plot_metadata(df, feature, \"ann_level_2\", width = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is the metadata. But indeed, one might be more interested in certain genes. So of course one can also color the UMAP by a gene ID. Lets say I want to color by the expression of **ACTB** ([ENSG00000075624](https://www.ensembl.org/Homo_sapiens/Gene/Summary?db=core;g=ENSG00000075624;r=7:5526409-5563902)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_idx = hlca_small.var_names.to_list().index(\"ENSG00000075624\")\n",
    "feature = hlca_small.X[:,column_idx].toarray().flatten()\n",
    "plot_metadata(df, feature, \"ACTB (ENSG00000075624)\", width = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to note that the docs mention that the raw counts are not batch corrected ([data.humancellatlas.org/hca-bio-networks/lung/atlases/lung-v1-0](https://data.humancellatlas.org/hca-bio-networks/lung/atlases/lung-v1-0)). To correct for batch effects would be too big of a computation though for my small computer. So I have to move forward without it for the sake of exploring this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Gene Expression Analysis\n",
    "\n",
    "No RNA-seq analysis is complete without a bit of differential gene expression analysis. I thought the easiest would be to focus on healthy samples and have a look at different groups of cells.\n",
    "\n",
    "First I have to decide on a annotation level and subset to healthy cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotnine as p9\n",
    "\n",
    "df = hlca_small.obs.copy()\n",
    "\n",
    "# Create a new DataFrame with the tissue and disease columns\n",
    "df = df[df.disease.isin([\"normal\"])].reset_index()\n",
    "(\n",
    "    p9.ggplot(df, p9.aes(x='ann_level_2')) +\n",
    "    p9.geom_bar(position='dodge') +\n",
    "    p9.theme_light() +\n",
    "    p9.labs(title='Cell Type Counts',\n",
    "            x='Cell type (Annotation Level 2)',\n",
    "            y='Count',\n",
    "            fill = \"Disease\") +\n",
    "    p9.geom_hline(yintercept = 100) + \n",
    "    p9.theme(axis_text_x=p9.element_text(rotation=90, hjust=1))\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remove small groups and set a threshold of 100 cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_counts = df['ann_level_2'].value_counts()\n",
    "valid_ann_levels = cell_counts[cell_counts >= 100].index\n",
    "\n",
    "hlca_small_filtered = hlca_small[(hlca_small.obs['ann_level_2'].isin(valid_ann_levels)) & (hlca_small.obs['disease'].isin([\"normal\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use scanpy to do a differential gene expression analysis between these classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(hlca_small_filtered, groupby='ann_level_2', method='t-test', use_raw = False)\n",
    "sc.tl.dendrogram(hlca_small_filtered, groupby=[\"ann_level_2\"])\n",
    "sc.pl.rank_genes_groups_heatmap(hlca_small_filtered, n_genes = 50,  use_raw=False, show_gene_labels=False, figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats a heatmap showing the top 50 differentially expressed genes across 6 annotated classes. Very cool how easy scanpy makes this type of analysis for me. \n",
    "\n",
    "Now I have satisfied my curiosity for now. I hope you enjoyed exploring the Human Lung Cell Atlas with me and you also now have a better idea what data it holds and what one can do with it.\n",
    "\n",
    "In the future I want to explore how I can use the annotations here to annotate new single-cell assays, but that's a topic for another post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproduce_hic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
